{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "356b10fee7e52806",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bec8edc03d0812a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('ratingsTrain.txt', header=0, delimiter='\\t', quoting=3)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7644fa261ce1e9ef",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "별점10점가자 1\n"
     ]
    }
   ],
   "source": [
    "print(train_data['document'][123], train_data['label'][123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd85934a-b940-419d-a6e1-2142e1d14502",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting JPype1>=0.7.0 (from konlpy)\n",
      "  Downloading JPype1-1.4.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (465 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.3/465.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lxml>=4.1.0 (from konlpy)\n",
      "  Downloading lxml-4.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy>=1.6 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from konlpy) (1.26.1)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from packaging->JPype1>=0.7.0->konlpy) (3.1.1)\n",
      "Downloading lxml-4.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml, JPype1, konlpy\n",
      "Successfully installed JPype1-1.4.1 konlpy-0.6.0 lxml-4.9.3\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1624e694e3b2004a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T08:05:20.627037Z",
     "start_time": "2023-11-22T08:05:20.599009Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "323c07a38c062e3f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-22T08:05:21.280507Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 감탄사, 조사들은 제거할 수 있도록 정의\n",
    "stop_words = set(['은', '는', '이', '가', '하', '아', '것', '들', '의', '있', '되', '수', '보', '주', '등', '한'])\n",
    "\n",
    "okt = Okt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7779b0ff51c1c264",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘', '정말', '좋다', '날씨', '네', '요']\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(review, okt, remove_stopwords=False, stop_words=None):\n",
    "    if stop_words is None:\n",
    "        stop_words = set()\n",
    "\n",
    "    try:\n",
    "        # 문장에서 한글만 뽑아냄\n",
    "        review_text = re.sub(\"[^가-힣ㄱ-하-ㅣ\\\\s]\", \"\", review)\n",
    "\n",
    "        # okt 라이브러리로 단어의 어간별로 분리\n",
    "        word_review = okt.morphs(review_text, stem=True)\n",
    "\n",
    "        # 감탄사와 조사 제거 - (suppose) 감탄사와 조사는 morphs가 분리시켜주지 않는 것으로 보임\n",
    "        if remove_stopwords:\n",
    "            word_review = [token for token in word_review if token not in stop_words]\n",
    "\n",
    "        return word_review\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "# 예시 사용\n",
    "review = \"오늘은 정말 좋은 날씨네요!\"\n",
    "preprocessed_review = preprocessing(review, okt, remove_stopwords=True, stop_words=stop_words)\n",
    "\n",
    "if preprocessed_review is not None:\n",
    "    print(preprocessed_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa0b4c15f77e9127",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 이상한 데이터 정제\n",
    "clean_train_review = []\n",
    "\n",
    "for review in train_data['document']:\n",
    "    if type(review) == str:\n",
    "        clean_train_review.append(preprocessing(review, okt, True, stop_words))\n",
    "    else:\n",
    "        clean_train_review.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26cd65b53a8b08bf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['더빙', '진짜', '짜증나다', '목소리'],\n",
       " ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍다', '않다'],\n",
       " ['너', '무재', '밓었', '다그', '래서', '보다', '추천', '다'],\n",
       " ['교도소', '이야기', '구먼', '솔직하다', '재미', '없다', '평점', '조정']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_review[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca3a5fb-c987-4721-8479-0bd9e503f86a",
   "metadata": {},
   "source": [
    "### Text to Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aee2ede9918ec4e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# 전체 순서를 만들고\n",
    "tokenizer.fit_on_texts(clean_train_review)\n",
    "\n",
    "# 단어의 위치를 숫자로 표시\n",
    "train_sequence = tokenizer.texts_to_sequences(clean_train_review)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 8\n",
    "\n",
    "# 최대 문장 길이는 8로 padding\n",
    "train_inputs = pad_sequences(train_sequence, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "# train label 만들기\n",
    "train_labels = np.array(train_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec5a6f2132687bad",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  466,    20,   266,   666,     0,     0,     0,     0],\n",
       "       [  606,     1,   220,  1461,    30,   971,   682,    24],\n",
       "       [  395,  2458, 25061,  2325,  5682,     2,   227,    13],\n",
       "       [ 6508,   110,  8143,   225,    61,     8,    31,  3623]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2116c241f0ba5441",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4219/4219 [==============================] - 334s 79ms/step - loss: 0.6057 - accuracy: 0.7581\n",
      "Epoch 2/5\n",
      "4219/4219 [==============================] - 329s 78ms/step - loss: 0.4725 - accuracy: 0.8387\n",
      "Epoch 3/5\n",
      "4219/4219 [==============================] - 328s 78ms/step - loss: 0.4266 - accuracy: 0.8702\n",
      "Epoch 4/5\n",
      "4219/4219 [==============================] - 328s 78ms/step - loss: 0.4550 - accuracy: 0.8822\n",
      "Epoch 5/5\n",
      "4219/4219 [==============================] - 327s 78ms/step - loss: 0.4135 - accuracy: 0.8995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f060ad14130>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10%는 Eval Data로 사용\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "\n",
    "# 데이터를 train과 eval로 분리\n",
    "from sklearn.model_selection import train_test_split\n",
    "input_train, input_eval, label_train, label_eval = train_test_split(train_inputs, train_labels, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Embedding, Conv1D\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Word Embedding\n",
    "word_size = len(tokenizer.word_index)+1\n",
    "model.add(Embedding(word_size, 128, input_length=MAX_SEQUENCE_LENGTH))\n",
    "\n",
    "# DNN Training, Activation은 relu\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# epoch을 5로 해서 간단히 학습\n",
    "model.fit(input_train, label_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7faeef7709a7dc62",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 1s 1ms/step - loss: 1.1693 - accuracy: 0.7368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1692878007888794, 0.7368000149726868]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(input_eval, label_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bed4db307d726c35",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def predict_review(sentence, model):\n",
    "    # 테스트 문장을 전처리\n",
    "    test_prepro = preprocessing(sentence, okt, True, stop_words)\n",
    "    test_review = []\n",
    "    test_review.append(test_prepro)\n",
    "    \n",
    "    # 전처리된 문장을 토큰화\n",
    "    test_token = tokenizer.texts_to_sequences(test_review)\n",
    "    test_seq = pad_sequences(test_token, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "    ret = model.predict(test_seq)\n",
    "    if ret > 0.5:\n",
    "        sentiment = \"긍정\"\n",
    "    elif ret < 0.5:\n",
    "        sentiment = \"부정\"\n",
    "    elif ret == 0.5:\n",
    "        sentiment = \"중립\"\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c961e998da36130",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'부정'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트\n",
    "predict_review('', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "634303ad-d536-4cfa-929a-8539a09c90b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('textSA_ver1.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
